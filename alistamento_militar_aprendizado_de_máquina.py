# -*- coding: utf-8 -*-
"""Alistamento militar - Aprendizado de Máquina.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Xybq8c-yM6I2dR4ZWZYq7Nqofs8Hx9s8

### Alistamento militar - Aprendizado de Máquina

Neste notebook é executado o treino dos classificadores Decision Tree e Random Forest. A análise gráfica pode ser encontrada em outro notebook no [github do projeto](https://github.com/rafaelgard/Data-Science-Aplicado-ao-Alistamento-Militar)
"""

#Faz a ligação com o banco de dados do Google
from google.colab import drive
drive.mount('/content/drive',force_remount=True)

import pandas as pd
import datetime
import matplotlib.pyplot as plt
import seaborn as sns
import sklearn
import numpy as np
import plotly.offline as py
import plotly.graph_objs as go
import matplotlib

# Commented out IPython magic to ensure Python compatibility.
# %%time
# #Importando o dataframe inicial atualizado
# 
# df = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/Alistamento Militar/df_atualizado_utf8.csv",sep=",",encoding='UTF-8')

# Define a coluna indice como índice da tabela, permitindo assim a realização da busca usando a função df.loc
df=df.set_index('ÍNDICE')

df.head()

"""# Analisando os dados"""

#Verificando a existencia de dados nulos
print("Dados nulos:")
print(df.isnull().sum())

print('Informações sobre o dataframe')
print(df.info())

"""### Analisandos os dados únicos em cada coluna"""

print('=================================================')
for coluna in df.columns:
  print('Coluna: ', coluna)
  print(np.unique(df[coluna], return_counts = True)[0])
  print('=================================================')

"""## Tratando os dados

### Tratando os valores das colunas de município de residência e UF de residência
"""

#Devido a existencia de cidades com o mesmo nome em estados diferentes, 
#se faz necessário cria uma coluna que identifique as cidades individualmente
df['CIDADE-ESTADO']=df['MUN_RESIDENCIA']+'-'+df['UF_RESIDENCIA']
df = df.drop(['MUN_RESIDENCIA','UF_RESIDENCIA'], axis=1)

"""### Filtrando os valores da coluna ano de nascimento"""

#Adequa o ano de nascimento para considerar apenas pessoas que podem de fato servir
df=df[df['ANO_NASCIMENTO']>=1962]
df=df[df['ANO_NASCIMENTO']<=1989]

"""### Filtrando os valores da coluna idade"""

#Adequa a idade para ficar entre 18 e 45 anos já que apenas nesta faixa de idade é possível se alistar
df=df[df['IDADE']>=18]
df=df[df['IDADE']<=45]

"""### Tratando os valores da coluna dispensa"""

#Verificando as colunas da coluna dispensa, podemos ver que temos valores 'Não informado' o que prejudica a análise.
#Esse caso será tratado a seguir
df['DISPENSA'].unique()

def dispensa(status):
  if status == 'Não informado':
    return 2

  if status == 'Sem dispensa':
    return 1

  if status == 'Com dispensa':
    return 0

#Padronizando a coluna dispensa
df['DISPENSA']=df['DISPENSA'].apply(lambda x: dispensa(x))

#Os dados da coluna dispensa com valor 'Não informado' são dropados
df=df[df['DISPENSA']!= 2]

#A coluna 'DISPENSA' é o target, logo deve ser eliminada do dataframe principal
target = df["DISPENSA"]
df = df.drop(['DISPENSA'], axis=1)

"""### Tratando os valores da coluna estado cívil"""

### Os termos 'Desquitado' e 'Separado Judicialmente', serão substituidos por 'divorciado'
df['ESTADO_CIVIL']=df['ESTADO_CIVIL'].replace('Desquitado', 'Divorciado')
df['ESTADO_CIVIL']=df['ESTADO_CIVIL'].replace('Separado Judicialmente', 'Divorciado')
df['ESTADO_CIVIL']=df['ESTADO_CIVIL'].replace('Viuvo', 'Viúvo')

df.head()

"""## Categorização dos dados"""

for col in ['CIDADE-ESTADO','PAIS_RESIDENCIA','ANO_NASCIMENTO','PAIS_NASCIMENTO','VINCULACAO_ANO','IDADE']:
    # Converte a coluna para 'category'
    df[col] = df[col].astype('category')
    # Cria uma nova coluna codificada
    df[col+'_new']=df[col].cat.codes
    # Elimina a coluna original
    df.drop(col, axis=1, inplace=True)
for col in ['ZONA_RESIDENCIAL','ESTADO_CIVIL','ESCOLARIDADE']:
    nova_col = pd.get_dummies(df[col])
    df = pd.concat([df,nova_col],axis=1)
    df.drop(col, axis=1,inplace=True)

df.head()

"""# Algoritmo de classificação

## Importa funções e modelos
"""

def decision_tree_classificador(train_X:pd.core.frame.DataFrame, test_X:pd.core.frame.DataFrame, train_y:pd.core.series.Series, test_y:pd.core.series.Series):
    #Importando as bibliotecas
    from sklearn.tree import DecisionTreeClassifier
    from sklearn.metrics import accuracy_score
    
    # Decision Tree
    #Define os parametros do modelo
    decision_tree = DecisionTreeClassifier(min_samples_split= 4, min_samples_leaf= 3, max_depth= 19, criterion= 'entropy')
    
    #Treina o modelo
    decision_tree.fit(train_X, train_y)
    
    #Calcula o score do modelo
    acc_decision_tree = round(decision_tree.score(test_X, test_y) * 100, 2)
    
    return decision_tree, acc_decision_tree #Retorna o modelo e o score do modelo

def random_forest_classificador(train_X:pd.core.frame.DataFrame, test_X:pd.core.frame.DataFrame, train_y:pd.core.series.Series, test_y:pd.core.series.Series):
    #Importando as bibliotecas
    from sklearn.ensemble import RandomForestClassifier
    from sklearn.metrics import accuracy_score
    
    # Random Forest
    #Define os parametros do modelo
    random_forest = RandomForestClassifier(n_estimators=20, max_depth=40, n_jobs=-1)

    #Treina o modelo
    random_forest.fit(train_X, train_y)
    
    #Calcula o score do modelo
    acc_random_forest = round(random_forest.score(test_X, test_y) * 100, 2)
    
    return random_forest, acc_random_forest #Retorna o modelo e o score do modelo

def avalia_classificador(clf, x_test, y_test):
  #Esta função avalia os classificadores
  from sklearn.metrics import precision_recall_fscore_support
  from sklearn.metrics import confusion_matrix,accuracy_score
  predictions = clf.predict(x_test)
  print('Relatório de precisão:\nprecision \t\t\t recall \t\t\t f-score \t\t\t support\n',
        precision_recall_fscore_support(y_test, predictions)[0],'\t',
        precision_recall_fscore_support(y_test, predictions)[1],
        '\t',precision_recall_fscore_support(y_test, predictions)[2],'\t',
        precision_recall_fscore_support(y_test, predictions)[3],'\n')
  print('Matriz de confusão:\n',confusion_matrix(y_test, predictions),'\n')
  print('Accuracy score:',accuracy_score(y_test, predictions)*100,'\n')

def melhores_features(modelo, train_X):
  #Extrai a importância de cada característica (feature)
  analise = pd.DataFrame({'Característica': list(train_X.columns),
                    'importancia': modelo.feature_importances_}).\
                      sort_values('importancia', ascending = False)
                      
  return(analise)

def curva_roc(clf, x_test, y_test):
  import matplotlib.pyplot as plt
  from sklearn.metrics import plot_roc_curve
  plot_roc_curve(clf, x_test, y_test)
  plt.show()

def gerador_de_dados_de_treino_e_teste(dataframe, target, ajustar_escala):
  # Gera os dados de treino e teste com escala já ajustada
  from sklearn.model_selection import train_test_split
  x_train, x_test, y_train, y_test = train_test_split(dataframe, target, test_size=0.3, random_state=30, stratify=target)
  
  # Se for escolhido ajustar escala, as escalas dos dados de treino e teste são ajustadas
  if ajustar_escala == True:
    x_train, x_test = ajustador_de_escala(x_train, x_test)

  return (x_train, x_test, y_train, y_test)

def ajustador_de_escala(x_train, x_test):
  #Ajusta a escala dos dados removendo outlyers e melhorando a acurácia do modelo
  from sklearn.neural_network import MLPClassifier
  from sklearn.preprocessing import RobustScaler
  
  #Ajusta as features
  scaler = RobustScaler()
  scaler.fit(x_train)
  x_train = scaler.transform(x_train)  
  x_test = scaler.transform(x_test)

  return (x_train, x_test)

def und_sampling(train_X:pd.core.frame.DataFrame,train_y:pd.core.series.Series):
#Gera os conjuntos de treino e teste balanceados por undersampling
    #Importando as bibliotecas
    from imblearn.under_sampling import RandomUnderSampler
    import seaborn as sns
    
    # Aplicando a técnica undersampling
    rus = RandomUnderSampler()

    #Novos conjuntos de treino gerados
    X_und, y_und = rus.fit_sample(train_X, train_y)

    # Verificar o balanceamento das classes
    print(pd.Series(y_und).value_counts())

    # Plotar a nova distribuição de classes
    sns.countplot(y_und)
    
    #Retorna os novos conjuntos de treino gerados
    return X_und, y_und

"""## Gera conjuntos de treino e teste"""

# Salva o nome das colunas
colunas=df.columns

# Cria os dados de treino e teste
train_X, test_X, train_y, test_y = gerador_de_dados_de_treino_e_teste(df, target, False)

# Libera memória ram
df=pd.DataFrame()
target=[]

"""# Treina classificadores

### Treinando o classificador 1: Decision Tree
"""

clf, acc_decision_tree=decision_tree_classificador(train_X, test_X, train_y, test_y)

print('clf',type(clf))
print('acc_decision_tree',type(acc_decision_tree))

"""### Avaliando o classificador 1"""

avalia_classificador(clf, test_X, test_y)
curva_roc(clf, test_X, test_y)

analise=melhores_features(clf, train_X)

# Imprime as caracteristicas mais importantes do modelo
print("As caracteristicas mais importantes do modelo são:")
print(analise)
analise.plot('Característica', 'importancia', figsize=(10,6), legend=False, title ='MELHORES FEATURES', grid =1)
plt.xticks(rotation=45)

"""## Treinando os classificadores com undersampling"""

train_X, train_y=und_sampling(train_X, train_y)
clf, acc_decision_tree=decision_tree_classificador(train_X, test_X, train_y, test_y)
avalia_classificador(clf, test_X, test_y)
curva_roc(clf, test_X, test_y)

"""### Treinando o classificador 2: Random Forest"""

clf, acc_random_forest=random_forest_classificador(train_X, test_X, train_y, test_y)

"""### Avaliando o classificador 2"""

avalia_classificador(clf, test_X, test_y)
curva_roc(clf, test_X, test_y)

print('Acurácia com o classificador Random Forest', print('acc_random_forest', acc_random_forest))